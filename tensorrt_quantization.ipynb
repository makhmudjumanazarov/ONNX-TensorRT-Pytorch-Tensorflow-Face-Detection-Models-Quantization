{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt \n",
    "import os \n",
    "import numpy as np \n",
    "import engine\n",
    "import pycuda.driver as cuda\n",
    "import torch \n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Lets check the file size of MS Paint exe \n",
    "# or you can use any file path\n",
    "file_path = r\"/home/airi/yolo/ONNX-TensorRT-Pytorch-Tensorflow-Face-Detection-Models-Quantization/models/yolov8n.engine\"\n",
    "print(file_size(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it possible to see tensorrt model weights?\n",
    "- No, it is not possible to directly view the weights of a TensorRT model. TensorRT is an optimization and inference acceleration library provided by NVIDIA, and it performs various optimizations on the model to improve its runtime performance on NVIDIA GPUs. During the optimization process, TensorRT quantizes and compresses the model, prunes unnecessary operations, and applies other optimizations that can significantly reduce the model size and improve inference speed.\n",
    "- As a result of these optimizations, the model weights are transformed into a format that is specific to TensorRT and not directly human-readable. The optimized model is typically saved in a binary format, such as a serialized engine file (.engine) or a frozen model file (.uff), which contains the compressed and optimized representation of the model.\n",
    "- If you need to inspect the weights or parameters of a model, you would typically need to access the original, unoptimized model format, such as a TensorFlow SavedModel or a PyTorch model, before it has been converted and optimized using TensorRT. Once the model has been optimized with TensorRT, it is not straightforward to retrieve the original weights in their original form.\n",
    "- However, if you have access to the original model and want to explore its weights, you can examine the model using the corresponding deep learning framework's tools and functions. For example, in TensorFlow, you can use the model's APIs to access and inspect individual layer weights. Similarly, in PyTorch, you can inspect the model parameters using the model's state_dict() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30/2023-13:33:24] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[09/30/2023-13:33:24] [TRT] [W] input \"input\" with shape: (1, 3, 640, 640) dtype: DataType.FLOAT\n",
      "[09/30/2023-13:33:24] [TRT] [W] output \"output\" with shape: (1, 5, 8400) dtype: DataType.FLOAT\n",
      "[09/30/2023-13:33:24] [TRT] [W] output \"onnx::Reshape_699\" with shape: (1, 65, 80, 80) dtype: DataType.FLOAT\n",
      "[09/30/2023-13:33:24] [TRT] [W] output \"onnx::Reshape_718\" with shape: (1, 65, 40, 40) dtype: DataType.FLOAT\n",
      "[09/30/2023-13:33:24] [TRT] [W] output \"onnx::Reshape_737\" with shape: (1, 65, 20, 20) dtype: DataType.FLOAT\n",
      "[09/30/2023-13:35:53] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[09/30/2023-13:35:53] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[09/30/2023-13:35:53] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[09/30/2023-13:35:53] [TRT] [W] - 53 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[09/30/2023-13:35:53] [TRT] [W] Build tensorrt engine finish.\n",
      "Save in /home/airi/yolo/ONNX-TensorRT-Pytorch-Tensorflow-Face-Detection-Models-Quantization/models/yolov8n.engine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "engine_build = engine.EngineBuilder('/home/airi/yolo/ONNX-TensorRT-Pytorch-Tensorflow-Face-Detection-Models-Quantization/models/yolov8n.onnx' , device)\n",
    "engine_build.seg = True\n",
    "engine_build.build(fp16=True,\n",
    "              input_shape=[1, 3, 640, 640],\n",
    "              iou_thres=0.65,\n",
    "              conf_thres=0.25,\n",
    "              topk=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Quantized file\n",
    "file_path = r\"/home/airi/yolo/ONNX-TensorRT-Pytorch-Tensorflow-Face-Detection-Models-Quantization/quant_models/quantized_yolov8n.engine\"\n",
    "print(file_size(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mahmud",
   "language": "python",
   "name": "mahmud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
